{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martacor2/corellian_spike/blob/main/RL_with_Corellian_Spike.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj-QuQOVPUdH"
      },
      "source": [
        "# Necessary imports\n",
        "\n",
        "It is only necessary to run the second cell if you will be importing files from Google Drive and you are using Google Colab to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vu2HNXn8GrtM"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from numpy.lib.type_check import nan_to_num\n",
        "import json\n",
        "from statistics import mode\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymE04qRvAJBO",
        "outputId": "a049854d-bcc4-4418-c08d-a1101d4da3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnS0TIT3P_sn"
      },
      "source": [
        "# Simulator Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNTimkCDfDPp"
      },
      "outputs": [],
      "source": [
        "from traitlets.config.loader import KeyValueConfigLoader\n",
        "class CorellianSpike:\n",
        "  def __init__(self,p,n=2,human=False, epsilon = 0, win_credits=True, connect=False):\n",
        "    self.n = n # Number of players\n",
        "    self.human = human\n",
        "    self.win_credits = win_credits\n",
        "    self.connect = connect\n",
        "\n",
        "    self.p = p # Policy\n",
        "    \n",
        "    self.homogeneous = type(self.p) == dict\n",
        "    self.last_played = 0 # tracks who was the player who finished the betting phase for recording purposes \n",
        "    self.final_bet = 0 # tracks the min bet for recording purposes\n",
        "    self.deck = [0,0]\n",
        "    self.folded_players = []\n",
        "    for i in range(-10, 11):\n",
        "      self.deck += [i] * 3\n",
        "    random.shuffle(self.deck)\n",
        "    self.discard = []\n",
        "    self.f = open('spike_data.txt','a')\n",
        "    self.epsilon = epsilon\n",
        "    self.states = set()\n",
        "\n",
        "    # Betting actions: 0 = raise, 1 = match, 2 = fold\n",
        "    # Buying a card: 3 = buy, 4 = don't buy\n",
        "    # Next card action: 5 = discard, 6 = swap w/ spike, 7 = swap w/ hand\n",
        "\n",
        "    self.end = False\n",
        "    \n",
        "    self.last_folded = []\n",
        "    self.pool = 0\n",
        "    self.last_gain = 0\n",
        "    self.players = [{'hand':[], 'spike':[], 'extra_card':[], 'money':50, 'folded': False, 'win':False, 'last_state':0, 'last_action':0, 'last_min_bet':0, 'last_reward':0} for i in range(self.n)]\n",
        "\n",
        "  def run_hand(self,hand): # izzie\n",
        "    \"\"\"\n",
        "    This function runs a hand of Corellian Spike.\n",
        "    No inputs or outputs, just updates tracked variables.\n",
        "    \"\"\"\n",
        "    self.round = 0\n",
        "    # Each player buys in with 2 credits\n",
        "    for player in range(self.n):\n",
        "      self.players[player]['money'] -= 2\n",
        "      self.pool += 2\n",
        "    self.deal_card()\n",
        "    if self.human:\n",
        "      print(\"Your starting hand is:\",self.players[0]['hand'])\n",
        "\n",
        "    if self.connect and hand != 0 and hand != 9:\n",
        "      for player in range(self.n):\n",
        "        if player not in self.last_folded:\n",
        "          self.record(player, connect_time = True)\n",
        "          self.players[player]['win'] = False\n",
        "\n",
        "      \n",
        "    self.bet(self.n-1)\n",
        "    self.round += 1\n",
        "    self.deal_spike()\n",
        "    for p in range(self.n):\n",
        "      if p not in self.folded_players:\n",
        "        s = self.players[p]['last_state']\n",
        "        sp = self.get_state(p,2)\n",
        "        self.record(p,s,action=self.players[p]['last_action'],decision=2,r=self.players[p]['last_reward'],sp=sp,min_bet=self.final_bet)\n",
        "    if self.human:\n",
        "      print(\"Your spike card is:\",self.players[0]['spike'])\n",
        "      for player in range(1,self.n):\n",
        "        print(\"Player\",player,\"has this spike card:\",self.players[player]['spike'])\n",
        "    for round in range(3):\n",
        "      #print(\"NEW ROUND\")\n",
        "      if len(self.deck) < self.n:\n",
        "        random.shuffle(self.discard)\n",
        "        self.deck += self.discard\n",
        "        self.discard = []\n",
        "      self.buy_card()\n",
        "      self.bet(self.n-1)\n",
        "      self.round += 1\n",
        "      if len(self.deck) < 3*self.n:\n",
        "        random.shuffle(self.discard)\n",
        "        self.deck += self.discard\n",
        "        self.discard = []\n",
        "      self.spike_dice()\n",
        "      if self.human:\n",
        "        print(\" \")\n",
        "\n",
        "    if self.human:\n",
        "      print(\"Your final cards:\",self.players[0]['hand'],self.players[0]['spike'])\n",
        "      for player in range(1,self.n):\n",
        "        print(\"Player\",player,\"final cards:\",self.players[player]['hand'],self.players[player]['spike'])\n",
        "\n",
        "    self.last_gain = self.pool\n",
        "    self.evaluate_hands()\n",
        "    for player in range(self.n):\n",
        "      if player not in self.folded_players and not self.players[player]['win']:\n",
        "        self.record(player)\n",
        "    if self.human:\n",
        "      if self.players[0]['win']:\n",
        "        print(\"You won the hand!\")\n",
        "      else:\n",
        "        print(\"You lost the hand. :(\")\n",
        "      print(\" \")\n",
        "      print(\"---\")\n",
        "      print(\" \")\n",
        "\n",
        "  def play_sabacc(self, k=10): #Izzie\n",
        "    \"\"\"\n",
        "    This function has the players play for k rounds or until someone loses all their money.\n",
        "    It also resets the 'folded' boolean after each hand.\n",
        "    \n",
        "    Returns: nothing\n",
        "    \"\"\"\n",
        "    win_counts = np.zeros(self.n)\n",
        "    for hand in range(k):\n",
        "      if hand == k-1:\n",
        "        self.end = True\n",
        "\n",
        "      #print(\"HAND #\"+str(hand))\n",
        "      # Reset the deck\n",
        "      self.deck = [0,0]\n",
        "      for i in range(-10, 11):\n",
        "        self.deck += [i] * 3\n",
        "      random.shuffle(self.deck)\n",
        "      self.discard = []\n",
        "      lost = False\n",
        "\n",
        "      # Play a hand\n",
        "      if self.human:\n",
        "        print(\"HAND\",hand)\n",
        "        print(\"You have\",self.players[0]['money'],\"credits.\")\n",
        "      self.run_hand(hand)\n",
        "      # Reset folding and cards figure out if anyone lost all their money\n",
        "      self.pool = 0\n",
        "      for player in range(self.n):\n",
        "        if self.players[player]['win']:\n",
        "          win_counts[player] += 1\n",
        "        self.players[player]['folded'] = False\n",
        "        self.players[player]['hand'] = []\n",
        "        self.players[player]['spike'] = []\n",
        "        self.players[player]['extra_card'] = []\n",
        "        self.last_folded = self.folded_players.copy()\n",
        "        self.folded_players = []\n",
        "        if self.players[player]['money'] <= 0:\n",
        "          # self.players[player]['folded'] = True\n",
        "          lost = True\n",
        "      if lost:\n",
        "        break\n",
        "    self.end = False\n",
        "    self.f.close()\n",
        "    return win_counts\n",
        "\n",
        "  def deal_card(self):  \n",
        "    #range 2 to deal two cards\n",
        "    for i in range(2):\n",
        "      for j in range(self.n):\n",
        "        if j in self.folded_players:\n",
        "          pass\n",
        "        else:\n",
        "          card = self.deck[0]\n",
        "          #assign card to a player\n",
        "          self.players[j]['hand'].append(card)\n",
        "          self.deck.pop(0)\n",
        "\n",
        "  def bet(self, last_player, player=0, min_bet=0): # izzie\n",
        "    \"\"\"\n",
        "    This is a recursive betting function.\n",
        "    No outputs, only updates tracked variables.\n",
        "\n",
        "    Inputs:\n",
        "     - Which player's turn it is to bet\n",
        "     - What the current minimum bet is (or they have to fold)\n",
        "    \"\"\"\n",
        "    # Stop running this if everyone has folded\n",
        "    if len(self.folded_players) == self.n:\n",
        "      return 2\n",
        "    # Skip the player if they have folded\n",
        "    if not self.players[player]['folded']:\n",
        "      # All in: player remains in game if no money. (Just skip them like they folded.)\n",
        "      if self.players[player]['money'] <= 0:\n",
        "        if player != last_player and self.n - len(self.folded_players) > 1:\n",
        "          return self.bet(player=(player+1)%self.n,last_player=last_player,min_bet=min_bet)\n",
        "        else:\n",
        "          return 2\n",
        "      else:\n",
        "        s = self.get_state(player,1)\n",
        "        if self.human and player==0:\n",
        "          action = None\n",
        "          print(\"The minimum bet is\",min_bet,\"credits. You have\",self.players[0]['money'],\"credits.\")\n",
        "          while not (action == 0 or action == 1 or action == 2):\n",
        "            try:\n",
        "              action = int(input(\"Type 0 to raise, 1 to match or stand, or 2 to fold: \"))\n",
        "            except:\n",
        "              print(\"An error occurred, try again.\")\n",
        "        else:\n",
        "          if self.homogeneous:\n",
        "            if np.random.uniform() < self.epsilon and self.epsilon !=0:\n",
        "              action = np.random.randint(0,2) # Look up this value\n",
        "            else: #if epsilon is indeed 0, or the random value from a uniform distribution is greater than epsilon\n",
        "              if s in self.p.keys():\n",
        "                action = self.p[s] # Look up this value\n",
        "              else:\n",
        "                action = 1\n",
        "          else:\n",
        "            if np.random.uniform() < self.epsilon and self.epsilon !=0:\n",
        "              action = np.random.randint(0,2) # Look up this value\n",
        "            else: #if epsilon is indeed 0, or the random value from a uniform distribution is greater than epsilon\n",
        "              if s in self.p[player].keys():\n",
        "                action = self.p[player][s]\n",
        "              else:\n",
        "                action = 1\n",
        "          if self.human:\n",
        "            print(\"Player\",player,\"took this action:\",action)\n",
        "        if self.n - len(self.folded_players) == 1: # Force this thing to match if it's the only one playing\n",
        "          action = 1\n",
        "        self.players[player]['last_action'] = action\n",
        "        self.players[player]['last_min_bet'] = min_bet\n",
        "        self.players[player]['last_state'] = s\n",
        "        # If raising\n",
        "        if action == 0:\n",
        "          self.pool += 2\n",
        "          self.players[player]['money'] -= 2\n",
        "          m = self.players[player]['money']\n",
        "          p = self.pool\n",
        "          # Recursively call function, last player to bet is the player directly before you\n",
        "          dec = self.bet(player=(player+1)%self.n,last_player=(player-1)%self.n,min_bet=2)\n",
        "          if dec!=2: # Only record if continuing betting\n",
        "            sp = self.get_state(player,dec,passing=True,money=m,pool=p)\n",
        "            self.record(player,s,action=action,decision=1,sp=sp,min_bet=2)\n",
        "          else:\n",
        "            self.players[player]['last_reward'] = self.get_reward(player,1,action,2)\n",
        "            self.last_played = player\n",
        "            self.final_bet = 2\n",
        "          return 1\n",
        "        # If matching\n",
        "        elif action == 1:\n",
        "          self.pool += min_bet\n",
        "          self.players[player]['money'] -= min_bet\n",
        "          m = self.players[player]['money']\n",
        "          p = self.pool\n",
        "          # Only call recursively if not the last person\n",
        "          if player != last_player:\n",
        "            dec = self.bet(player=(player+1)%self.n,last_player=last_player,min_bet=min_bet)\n",
        "          else:\n",
        "            dec = 2\n",
        "          if dec!=2: # Only record if continuing betting\n",
        "            sp = self.get_state(player,dec,passing=True,money=m,pool=p)\n",
        "            self.record(player,s,action=action,decision=1,sp=sp,min_bet=min_bet)\n",
        "          else:\n",
        "            #self.players[player]['last_state'] = self.get_state(player,1)\n",
        "            self.players[player]['last_reward'] = self.get_reward(player,1,action,min_bet)\n",
        "            self.last_played = player\n",
        "            self.final_bet = min_bet\n",
        "          return dec\n",
        "        # If folding\n",
        "        else:\n",
        "          self.players[player]['folded'] = True\n",
        "          self.folded_players.append(player)\n",
        "          # Stay in the same state, never will transition\n",
        "          self.players[player]['last_reward'] = self.get_reward(player,1,action,min_bet)\n",
        "          if player != last_player:\n",
        "            dec = self.bet(player=(player+1)%self.n,last_player=last_player,min_bet=min_bet)\n",
        "          else:\n",
        "            dec = 2\n",
        "          self.record(player,s,action=action,sp=0)\n",
        "          return dec\n",
        "    else:\n",
        "      if player == last_player:\n",
        "        return 2 # Don't keep playing if the last player has already folded\n",
        "      else:\n",
        "        return self.bet(player=(player+1)%self.n,last_player=last_player,min_bet=min_bet)\n",
        "\n",
        "  def deal_spike(self): \n",
        "    for j in range(self.n):\n",
        "      if j in self.folded_players:\n",
        "        pass\n",
        "      else:\n",
        "        card = self.deck[0]\n",
        "        #assign card to a player\n",
        "        self.players[j]['spike'].append(card)\n",
        "        self.deck.pop(0)\n",
        "\n",
        "  def buy_card(self): # max\n",
        "    for j in range(self.n):\n",
        "      if j in self.folded_players:\n",
        "        pass\n",
        "      else:\n",
        "        self.players[j]['hand'].sort()\n",
        "        s = self.get_state(j,2)\n",
        "        if self.human and j==0:\n",
        "          action = None\n",
        "          print(\"You have\",self.players[0]['money'],\"credits.\")\n",
        "          while not (action == 3 or action == 4):\n",
        "            try:\n",
        "              action = int(input(\"Type 3 to buy a card for 2 credits or 4 to do nothing: \"))\n",
        "            except:\n",
        "              print(\"An error occurred, try again.\")\n",
        "        else:\n",
        "          if self.homogeneous:\n",
        "            if np.random.uniform() < self.epsilon and self.epsilon !=0:\n",
        "              action = np.random.randint(3,4) # Look up this value\n",
        "            else: #if epsilon is indeed 0, or the random value from a uniform distribution is greater than epsilon\n",
        "              if s in self.p.keys():\n",
        "                action = self.p[s] # Look up this value\n",
        "              else:\n",
        "                action = 4\n",
        "          else:\n",
        "            if np.random.uniform() < self.epsilon and self.epsilon !=0:\n",
        "              action = np.random.randint(3,4) # Look up this value\n",
        "            else: #if epsilon is indeed 0, or the random value from a uniform distribution is greater than epsilon\n",
        "              if s in self.p[j].keys():\n",
        "                action = self.p[j][s]\n",
        "              else: action = 4\n",
        "          if self.human:\n",
        "            print(\"Player\",j,\"took this action:\",action)\n",
        "        if action == 3 and self.players[j]['money'] > 0: # buy card\n",
        "          self.players[j]['last_action'] = 3\n",
        "          self.players[j]['money'] -= 2 \n",
        "          self.pool += 2\n",
        "          card = self.deck[0]\n",
        "          self.players[j]['extra_card'].append(card)\n",
        "          self.deck.pop(0)\n",
        "          sp = self.get_state(j,3)\n",
        "          self.record(j,s,decision=2,sp=sp)\n",
        "          if self.human and j==0:\n",
        "            action = None\n",
        "            print(\"Your hand is:\",self.players[0]['hand'])\n",
        "            print(\"Your spike card is:\",self.players[0]['spike'])\n",
        "            print(\"Your extra card is:\",self.players[0]['extra_card'])\n",
        "            while not (action == 5 or action == 6 or action == 7 or action == 8):\n",
        "              try:\n",
        "                action = int(input(\"Type 5 to discard, 6 to swap with the spike card, 7 to swap with the lower hand card, or 8 to swap with the higher hand card: \"))\n",
        "              except:\n",
        "                print(\"An error occurred, try again.\")\n",
        "          else:\n",
        "            if self.homogeneous:\n",
        "              if np.random.uniform() < self.epsilon and self.epsilon !=0:\n",
        "                action = np.random.randint(5,8) # Look up this value\n",
        "              else: #if epsilon is indeed 0, or the random value from a uniform distribution is greater than epsilon\n",
        "                if sp in self.p.keys():\n",
        "                  action = self.p[sp] # Look up this value\n",
        "                else:\n",
        "                  action = 5\n",
        "            else:\n",
        "              if np.random.uniform() < self.epsilon and self.epsilon !=0:\n",
        "                action = np.random.randint(5,8) # Look up this value\n",
        "              else: #if epsilon is indeed 0, or the random value from a uniform distribution is greater than epsilon\n",
        "                if sp in self.p[j].keys():\n",
        "                  action = self.p[j][sp]\n",
        "                else:\n",
        "                  action = 5\n",
        "            if self.human:\n",
        "              print(\"Player\",j,\"took this action:\",action)\n",
        "          self.players[j]['last_action'] = action\n",
        "          if action == 5: # discard bought card\n",
        "            self.discard.append(card)\n",
        "          elif action == 6: # swap spike\n",
        "            self.players[j]['spike'].append(card)\n",
        "            self.discard.append(self.players[j]['spike'].pop(0))\n",
        "            if self.human and j!=0:\n",
        "              print(\"Player\",j,\"has a new spike card:\",self.players[j]['spike'])\n",
        "          elif action == 7: # swap with lower hand card\n",
        "            self.discard.append(self.players[j]['hand'].pop(0))\n",
        "            self.players[j]['hand'].append(card)\n",
        "          elif action == 8: # swap with higher hand card\n",
        "            self.discard.append(self.players[j]['hand'].pop(1))\n",
        "            self.players[j]['hand'].append(card)\n",
        "          else:\n",
        "            print('invalid action')\n",
        "          self.players[j]['extra_card'] = []\n",
        "          self.record(j,sp,decision=3,sp=self.get_state(j,1))\n",
        "        else: # do not buy card\n",
        "          self.players[j]['last_action'] = 4\n",
        "          self.record(j,s,action=4,decision=2,sp=self.get_state(j,1))\n",
        "        \n",
        "  def spike_dice(self): # max\n",
        "    roll_1 = random.randint(1, 6)\n",
        "    roll_2 = random.randint(1, 6)\n",
        "\n",
        "    if self.human:\n",
        "      print(\"Spike dice roll results:\",roll_1,roll_2)\n",
        "\n",
        "    if roll_1 == 1 and roll_2 == 1:  # Replace Spike\n",
        "      for j in range(self.n):\n",
        "        if j in self.folded_players:\n",
        "          pass\n",
        "        else:\n",
        "          self.discard.append(self.players[j]['spike'].pop(0))\n",
        "      #internally checks for folded, deals spike to every player that has not folded\n",
        "      self.deal_spike()\n",
        "      if self.human:\n",
        "        print(\"Your new spike card is:\",self.players[0]['spike'])\n",
        "        for player in range(self.n):\n",
        "          print(\"Player\",player,\"has this spike card:\",self.players[player]['spike'])\n",
        "\n",
        "    \n",
        "    if roll_1 == roll_2: # Replace Hand \n",
        "      for j in range(self.n):\n",
        "        if j in self.folded_players:\n",
        "          pass\n",
        "        else:\n",
        "          self.discard.append(self.players[j]['hand'].pop(0))  \n",
        "          self.discard.append(self.players[j]['hand'].pop(0))\n",
        "      #deal card applies to all players, internaly checks for folding\n",
        "      self.deal_card()\n",
        "      if self.human and 0 not in self.folded_players: #you have not folded\n",
        "        print(f\"Your new hand is:\",self.players[0]['hand'])\n",
        "        # for j in range(1,self.n):\n",
        "        #   print(f\"Check player {j}:\",self.players[j]['hand'])\n",
        "\n",
        "    if self.round == 4:\n",
        "      pass\n",
        "    else:\n",
        "      for player in range(self.n):\n",
        "        if player not in self.folded_players:\n",
        "          s = self.players[player]['last_state']\n",
        "          self.record(player,s,action=self.players[player]['last_action'],decision=2,r=self.players[player]['last_reward'],sp=self.get_state(player,2),min_bet=self.final_bet)\n",
        "\n",
        "\n",
        "  def tie_breaker(self,winner_dict,p_win):\n",
        "    \"\"\"\n",
        "    Deals with tie breaking rules\n",
        "    \"\"\"\n",
        "    #just to get it out of the way, check if players literally have the same hand\n",
        "    if (len(set([element for element in winner_dict['cards']]))==1):\n",
        "        #everyone has the same hand\n",
        "        n_win = np.random.choice([element for element in winner_dict['player']])\n",
        "        k = winner_dict['player'][n_win] # who is it that won\n",
        "        self.players[k]['win'] = True\n",
        "        self.players[k]['money']+= self.pool\n",
        "        self.record(k)\n",
        "        #reset the pool\n",
        "        self.pool = 0\n",
        "        return k\n",
        "\n",
        "    else:\n",
        "        #there are multiple winners --> first tie breaker rule says whoever has the lowest positive sum wins\n",
        "        #IF THE SUM IS POSITIVE (FOR ALL CARDS), TAKE THE LOWEST ONE TO WIN\n",
        "        #IF HIGHEST SUM OF POSITIVE CARDS \n",
        "        #IF HIGHEST SINGLE VALUE CARD (POSITIVE)\n",
        "        # GIVE A RANDOM PLAYER THE WIN\n",
        "\n",
        "        p_points = [winner_dict['points'][i] for i in p_win]\n",
        "\n",
        "        pos_score = [np.sum(element) for element in p_points if element>=0]                #get the positive/zero score of a player's hand\n",
        "        positive_winner = [i for i, x in enumerate(pos_score) if x == min(pos_score)]                  #get the player with the lowest positive sum in their hand    fixed .min()\n",
        "\n",
        "        # If all players have negative sums, keep the same list of players to tiebreak between\n",
        "        if len(positive_winner) == 0:\n",
        "          positive_winner = [i for i, x in enumerate(p_win)] \n",
        "\n",
        "        if len(positive_winner) == 1:\n",
        "            #found only one person with the lowest positive sum, they win\n",
        "            k = winner_dict['player'][p_win[positive_winner[0]]] #who is it\n",
        "            self.players[k]['win'] = True\n",
        "            self.players[k]['money']+=self.pool\n",
        "            self.record(k)\n",
        "            self.pool = 0\n",
        "            return(k)\n",
        "            \n",
        "        else:\n",
        "            #found multiple playes with the same lowest positive sum--> second tie breaker rule says whoever has highest sum of positive cards wins\n",
        "            #get the players that are ties\n",
        "            p_win = [p_win[i] for i in positive_winner]\n",
        "\n",
        "            high_positive_sum = []\n",
        "            for i in p_win:\n",
        "               positive_cards = [card for card in winner_dict['cards'][i] if card>=0]\n",
        "               high_positive_sum.append(np.sum(positive_cards))\n",
        "\n",
        "            high_pos_sum_winner = [i for i, x in enumerate(high_positive_sum) if x == max(high_positive_sum)] # .max()\n",
        "\n",
        "            # If none of the players have positive cards, keep the same list of players to tiebreak between\n",
        "            if len(high_pos_sum_winner) == 0:\n",
        "              high_pos_sum_winner = [i for i, x in enumerate(p_win)] \n",
        "\n",
        "            if len(high_pos_sum_winner) == 1:\n",
        "              #found only one person with the lowest positive sum, they win\n",
        "              k = winner_dict['player'][p_win[high_pos_sum_winner[0]]] #who is it\n",
        "              self.players[k]['win'] = True\n",
        "              self.players[k]['money']+= self.pool\n",
        "              self.record(k)\n",
        "              self.pool = 0\n",
        "              return(k)\n",
        "\n",
        "            else:\n",
        "                #found multiple playes with the same  absolute highest single value card--> third tie breaker rule says whoever has the highest positive single value card wins\n",
        "                p_win = [p_win[i] for i in high_pos_sum_winner]\n",
        "\n",
        "                high_positive_card = []                                 #must check which one has the absolute highest single value card\n",
        "                for i in p_win:\n",
        "                    positive_cards = [card for card in winner_dict['cards'][i] if card>=0]\n",
        "                    if len(positive_cards) > 0:\n",
        "                      high_positive_card.append(np.max(positive_cards))\n",
        "                    else:\n",
        "                      high_positive_card.append(0)\n",
        "\n",
        "                #find the player with the highest card in hand\n",
        "                high_pos_card_winner = [i for i, x in enumerate(high_positive_card) if x == max(high_positive_card)] #.max()\n",
        "\n",
        "                # Again, dealing with if no one has positive cards\n",
        "                if len(high_pos_card_winner) == 0:\n",
        "                  high_pos_card_winner = [i for i, x in enumerate(p_win)] \n",
        "\n",
        "                if len(high_pos_card_winner) == 1:\n",
        "                    #found only one person with the lowest positive sum, they win\n",
        "                    k = winner_dict['player'][p_win[high_pos_card_winner[0]]] #who is it\n",
        "                    self.players[k]['win'] = True\n",
        "                    self.players[k]['money']+= self.pool\n",
        "                    self.record(k)\n",
        "                    self.pool = 0\n",
        "                    return k\n",
        "\n",
        "                else:\n",
        "                    #multiple people have the idiot's array, they all won! Randomly pick a winner\n",
        "                    ind = random.randint(0,len(high_pos_card_winner)-1)\n",
        "                    #n_win = np.random.choice(winner_dict['player'][p_win[high_pos_card_winner]])\n",
        "                    n_win = winner_dict['player'][p_win[high_pos_card_winner[ind]]]\n",
        "                    self.players[n_win]['win'] = True\n",
        "                    self.players[n_win]['money']+= self.pool\n",
        "                    self.record(n_win)\n",
        "                    #reset the pool\n",
        "                    self.pool = 0\n",
        "                    return n_win\n",
        "  \n",
        "  def evaluate_hands(self, special = False): #marta\n",
        "    \"\"\"\n",
        "    This function evaluates players' hands at the end of a game\n",
        "\n",
        "    Inputs:\n",
        "     - special (Boolean): consider special hands or not\n",
        "\n",
        "    No outputs - updates tracked values\n",
        "    \"\"\"\n",
        "\n",
        "    #---------------------TO-DO: need to add intermediate state for evaluating hands ----------------#\n",
        "\n",
        "    winner_dict = {'player':[], 'cards':[], 'points': []}                                              #keep track of the player points to evaluate the winners\n",
        "    for p in range(self.n):\n",
        "      if p in self.folded_players:\n",
        "        pass\n",
        "      else:\n",
        "        #player -> the player number (a list of ints/floats)\n",
        "        winner_dict['player'].append(p)\n",
        "        #cards-> the player's 3 hand combo (a list of lists)\n",
        "        winner_dict['cards'].append(tuple(self.players[p]['hand']+self.players[p]['spike']))\n",
        "        #points-> the player's points from the 3 hand combo (a list of floats)\n",
        "        winner_dict['points'].append(np.sum(self.players[p]['hand']+self.players[p]['spike']))\n",
        "\n",
        "    if self.human:\n",
        "      print(winner_dict)\n",
        "\n",
        "    if special:\n",
        "      #check the special hands!\n",
        "      indices = [i for i, x in enumerate(winner_dict['cards']) if x == [2,3,0]]\n",
        "\n",
        "      if len(indices) == 1:\n",
        "        #someone has the idiot's array, they won!\n",
        "        k = winner_dict['player'][indices[0]] # who is it that won\n",
        "        self.players[k]['win'] = True\n",
        "        self.players[k]['money']+=self.pool\n",
        "        self.record(k)\n",
        "        self.pool = 0\n",
        "        return k\n",
        "\n",
        "      elif len(indices) > 1:\n",
        "        #multiple people have the idiot's array, they all won! Randomly pick a winner\n",
        "        n_win = np.random.choice(indices)\n",
        "        k = winner_dict['player'][n_win] # who is it that won\n",
        "        self.players[k]['win'] = True\n",
        "        self.players[k]['money']+= self.pool\n",
        "        self.record(k)\n",
        "        #reset the pool\n",
        "        self.pool = 0\n",
        "        return k\n",
        "\n",
        "      else:\n",
        "        #no one has the special hand, however, let's check prime sabacc\n",
        "        indices = [i for i, x in enumerate(winner_dict['cards']) if x == [10,-10,0]]\n",
        "        \n",
        "        if len(indices) == 1:\n",
        "           #someone has prime sabacc, they won!\n",
        "           k = winner_dict['player'][indices[0]] # who is it that won\n",
        "           self.players[k]['win'] = True\n",
        "           self.players[k]['money']+=self.pool\n",
        "           self.record(k)\n",
        "           self.pool = 0\n",
        "           return k\n",
        "\n",
        "        elif len(indices) > 1:\n",
        "            #multiple people have the prime sabacc, they all won! Randomly pick a winner\n",
        "            n_win = np.random.choice(indices)\n",
        "            k = winner_dict['player'][n_win] # who is it that won\n",
        "            self.players[k]['win'] = True\n",
        "            self.players[k]['money']+= self.pool\n",
        "            self.record(k)\n",
        "            #reset the pool\n",
        "            self.pool = 0\n",
        "            return k\n",
        "            \n",
        "        else:\n",
        "            #no one has special hands, run as usual\n",
        "            #consider the absolute value of the points and find the player with the lowest sum\n",
        "            p_win = [i for i, x in enumerate(winner_dict['points']) if np.abs(x) == min(np.absolute(winner_dict['points']))]   \n",
        "            \n",
        "        if len(p_win) == 1:    \n",
        "            #there is only one winner and they have the lowest number of points, give them money and reset the pool\n",
        "            k = winner_dict['player'][p_win[0]] # who is it that won\n",
        "            self.players[k]['win'] = True\n",
        "            self.players[k]['money']+=self.pool\n",
        "            self.record(k)\n",
        "            self.pool = 0\n",
        "            return k\n",
        "            \n",
        "        elif len(p_win) > 1:\n",
        "            return self.tie_breaker(winner_dict, p_win)\n",
        "        else:\n",
        "            print('Could not find a winner',len(self.folded_players))\n",
        "\n",
        "    else: #we are not running with special hands\n",
        "        #consider the absolute value of the points and find the player with the lowest sum\n",
        "        p_win = [i for i, x in enumerate(winner_dict['points']) if np.abs(x) == min(np.absolute(winner_dict['points']))]                  \n",
        "        if len(p_win) == 1:    \n",
        "            #there is only one winner and they have the lowest number of points, give them money and reset the pool\n",
        "            k = winner_dict['player'][p_win[0]] # who is it that won\n",
        "            self.players[k]['win'] = True\n",
        "            self.players[k]['money']+=self.pool\n",
        "            self.record(k)\n",
        "            self.pool = 0\n",
        "            return k\n",
        "            \n",
        "        elif len(p_win) > 1:\n",
        "            return self.tie_breaker(winner_dict, p_win)\n",
        "        else:\n",
        "            print('Could not find a winner',len(self.folded_players))\n",
        "\n",
        "  def get_state(self,player,decision,passing=False,money=None,pool=None): # Izzie\n",
        "    \"\"\"\n",
        "    Calculates the state for a given player at a given decision round.\n",
        "    # Example: Betting round at the beginning, holds a Prime Sabacc\n",
        "    # State = 10001000\n",
        "    # Example 2: Buying a card, holding 5,5,5, has 55 credits, 45 in the pool\n",
        "    # State = 29000605\n",
        "    # Example 3: First round deciding what to do with fourth card (-5), holding 2,3,3\n",
        "    # State = 38051000\n",
        "    \"\"\"\n",
        "    # Round = 1, 2, 3\n",
        "    # Decision = 1, 2, 3 per the project proposal\n",
        "    # Sum of cards not abs value, abs value is capped at 9, add 10 (two digits)\n",
        "    SUM = sum(self.players[player]['hand']) \n",
        "    if len(self.players[player]['spike']) > 0:\n",
        "      SUM += self.players[player]['spike'][0]\n",
        "    #option - skip 1, make it so that 10 is zero\n",
        "    if SUM > 9:\n",
        "      SUM = 9\n",
        "    elif SUM < -9:\n",
        "      SUM = -9\n",
        "    SUM += 10\n",
        "    # Extra = extra card + 10 (two digits)\n",
        "    if len(self.players[player]['extra_card'])==0:\n",
        "      extra = 0\n",
        "    else:\n",
        "      extra = self.players[player]['extra_card'][0] + 10\n",
        "    # Money, divide by 10 and round (two digits)\n",
        "    if not passing:\n",
        "      money = np.round(self.players[player]['money']/10)\n",
        "    else:\n",
        "      money = np.round(money/10)\n",
        "    if money > 9:\n",
        "      money = 9\n",
        "    if money < 0:\n",
        "      money = 0\n",
        "    # Pool, divide by 2 and round (two digits)\n",
        "    if not passing:\n",
        "      pool = np.round(self.pool/10)\n",
        "    else:\n",
        "      pool = np.round(pool/10)\n",
        "    if pool > 9:\n",
        "      pool = 9\n",
        "    # State = Round * 10^9 + Decision * 10^8 + Sum * 10^6 + extra * 10^4 + Money * 10^2 + Pool\n",
        "    state = self.round*10**7 + decision*10**6 + SUM*10**4 + extra*10**2 + money*10 + pool\n",
        "    # Keep track of last state for calling record() during evaluate_hands\n",
        "    #self.players[player]['last_state'] = int(state)\n",
        "    return int(state)\n",
        "\n",
        "  def record(self,player,state=None,action=None,r=None,decision=None,sp=None,min_bet=0,connect_time=False): # Izzie\n",
        "    if self.round == 4 and (not self.connect or self.end):\n",
        "      self.f.write(str(self.players[player]['last_state']))\n",
        "      self.states.add(self.players[player]['last_state'])\n",
        "      self.f.write(',')\n",
        "      self.f.write(str(self.players[player]['last_action']))\n",
        "      self.f.write(\",\")\n",
        "      self.f.write(str(self.players[player]['last_reward'] + self.get_reward(player)))\n",
        "      self.f.write(\",\")\n",
        "      self.f.write('0')\n",
        "      self.f.write(\"\\n\")\n",
        "    \n",
        "    elif connect_time:\n",
        "      self.f.write(str(self.players[player]['last_state']))\n",
        "      self.states.add(self.players[player]['last_state'])\n",
        "      self.f.write(',')\n",
        "      self.f.write(str(self.players[player]['last_action']))\n",
        "      self.f.write(\",\")\n",
        "      if action == 2:\n",
        "        self.f.write(\"0\")\n",
        "      else:\n",
        "        self.f.write(str(self.players[player]['last_reward'] + self.get_reward(player, connect_time=True)))\n",
        "      self.f.write(\",\")\n",
        "      self.f.write(str(self.get_state(player,1)))\n",
        "      self.f.write(\"\\n\")\n",
        "\n",
        "    elif not self.round==4 and (not action == 2 or self.end):\n",
        "      self.f.write(str(state))\n",
        "      self.states.add(state)\n",
        "      self.f.write(\",\")\n",
        "      if action == None:\n",
        "        action = self.players[player]['last_action']\n",
        "      self.f.write(str(action))\n",
        "      self.f.write(\",\")\n",
        "      if r == None:\n",
        "        r = self.get_reward(player,decision,action,min_bet)\n",
        "      self.f.write(str(r))\n",
        "      self.f.write(\",\")\n",
        "      self.f.write(str(sp))\n",
        "      self.f.write(\"\\n\")\n",
        "  \n",
        "  def get_reward(self,player,decision=None,action=None,min_bet=0,connect_time=False): # Izzie\n",
        "    if self.win_credits:\n",
        "      # If the game is over...\n",
        "      if self.round == 4 and self.players[player]['win']:\n",
        "        # Reward on winning = 31*gain = (1+highest possible sum)*gain\n",
        "        return self.pool\n",
        "      elif connect_time and self.players[player]['win']:\n",
        "        return self.last_gain\n",
        "      else:\n",
        "        # Reward in betting round = - (1+abs(sum of cards in hand)) * bet amount\n",
        "        if decision == 1 and action == 0:\n",
        "          return -min_bet\n",
        "        elif decision == 1 and action == 1:\n",
        "          return -min_bet\n",
        "        # Reward for buying a card = - (1+abs(min(sums of possible combinations of 3 of 4 cards)))*3/4) * 2\n",
        "        elif decision == 2 and action == 3:\n",
        "          return -2\n",
        "        # No reward for losing or card rounds\n",
        "        else:\n",
        "          return 0\n",
        "    else:\n",
        "      # If the game is over...\n",
        "      if self.round == 4 and self.players[player]['win']:\n",
        "        # Reward on winning = 31*gain = (1+highest possible sum)*gain\n",
        "        return 31*self.pool\n",
        "      elif connect_time and self.players[player]['win']:\n",
        "        return self.last_gain\n",
        "      else:\n",
        "        # Reward in betting round = - (1+abs(sum of cards in hand)) * bet amount\n",
        "        if decision == 1 and action == 0:\n",
        "          SUM = sum(self.players[player]['hand']) \n",
        "          if len(self.players[player]['spike']) > 0:\n",
        "            SUM += self.players[player]['spike'][0]\n",
        "          SUM = abs(SUM)\n",
        "          return -(1+abs(SUM))*min_bet\n",
        "        elif decision == 1 and action == 1:\n",
        "          SUM = sum(self.players[player]['hand']) \n",
        "          if len(self.players[player]['spike']) > 0:\n",
        "            SUM += self.players[player]['spike'][0]\n",
        "          SUM = abs(SUM)\n",
        "          return -(1+abs(SUM))*min_bet\n",
        "        # Reward for buying a card = - (1+abs(min(sums of possible combinations of 3 of 4 cards)))*3/4) * 2\n",
        "        elif decision == 2 and action == 3:\n",
        "          sums = []\n",
        "          for ind in range(4):\n",
        "            cards = (self.players[player]['hand'] + self.players[player]['spike'] + self.players[player]['extra_card']).copy()\n",
        "            del(cards[ind])\n",
        "            sums.append(abs(sum(cards)))\n",
        "          return -(1+abs(min(sums))*3/4)*2\n",
        "        # No reward for losing or card rounds\n",
        "        else:\n",
        "          return 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-fEsI6yQYk3"
      },
      "source": [
        "# Policy generator code\n",
        "\n",
        "This function generates a policy that can be inputted into the simulator. By default, this policy will always match bets and not buy a card. If r=True in the arguments, a completely random policy will be generated. If fold=2, then this random policy will fold 33% of the time. If this behavior is not desired, then setting fold=1 will generate a random policy that matches half the time and raises the other half of the time.\n",
        "\n",
        "Running this cell block also prints the number of states that are generated for that number of players. More states means Q-learning will take longer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt9vzGin_UCz",
        "outputId": "3eb07e1c-5b8f-48c6-89a6-b4eaa33fdddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "231040\n"
          ]
        }
      ],
      "source": [
        "# Let's create an initial policy!\n",
        "\n",
        "def generate_policy(player_number,fold=2,r=False):\n",
        "  \"\"\"\n",
        "  The state_lookup dictionary is generated such that the key is the state recorded, and it return the enumeration corresponding to that state\n",
        "  \"\"\"\n",
        "  policy = {}\n",
        "  state_lookup = {}\n",
        "  #reserved the first count for the terminal state\n",
        "  count = 1\n",
        "  for round in range(0,4):\n",
        "      for decision in range(3):\n",
        "          for sum in range(1,20): #19): #keeping track of negative sums now\n",
        "              for extra in range(21):\n",
        "                  # With max 8 players, most money you could win is 400 credits, not accounting for buying things\n",
        "                  for money in range(10):\n",
        "                      # The amount of money in the pool is limited by what the player has\n",
        "                      for pool in range(10):\n",
        "                        if money + pool <= player_number*5:\n",
        "                          if round == 0:\n",
        "                            if extra == 0:\n",
        "                              state = (round)*10**7 + (decision + 1)*10**6 + sum*10**4 + extra*10**2 + money*10 + pool\n",
        "                              if decision+1 == 1:\n",
        "                                if r:\n",
        "                                  policy[state] = random.randint(0,fold)\n",
        "                                else:\n",
        "                                  policy[state] = 1\n",
        "                                state_lookup[state] = count\n",
        "                                count+=1\n",
        "                          else:\n",
        "                            state = (round)*10**7 + (decision + 1)*10**6 + sum*10**4 + extra*10**2 + money*10 + pool\n",
        "                            if decision+1 == 1:\n",
        "                                if r:\n",
        "                                  policy[state] = random.randint(0,fold)\n",
        "                                else:\n",
        "                                  policy[state] = 1\n",
        "                            if decision+1 == 2:\n",
        "                                if r:\n",
        "                                  policy[state] = random.randint(3,4)\n",
        "                                else:\n",
        "                                  policy[state] = 4\n",
        "                            if decision+1 == 3:\n",
        "                                if r:\n",
        "                                  policy[state] = random.randint(5,8)\n",
        "                                else:\n",
        "                                  policy[state] = 5\n",
        "                            state_lookup[state] = count\n",
        "                            count+=1\n",
        "  state_lookup[0] = 0\n",
        "  # print(count)\n",
        "\n",
        "  return policy, state_lookup\n",
        "\n",
        "policy, state_lookup = generate_policy(2)\n",
        "\n",
        "print(len(list(policy.keys())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnV96QKzR5WK"
      },
      "source": [
        "# Q-Learning\n",
        "\n",
        "The first cell block contains functions necessary for running Q-learning. The second cell runs Q-learning to obtain an optimal policy. In each iteration, data is generated by running 2000 simulations, then the action-value function is approximated. The number of iterations can be set with tot_iter, the number of players with n_player, and the number of hands with n_hands. This will create a text file with the \"optimal\" policy.\n",
        "\n",
        "Before running the code, make sure to change the file locations in line 112 in cell 1 and lines 17, 27, 34, and 44 in cell 2.\n",
        "\n",
        "The third cell outputs a graph that shows how many states were explored over iterations. If all went well, the curve should initially rapidly decrease, then level out.\n",
        "\n",
        "The fourth cell creates a graph that shows how the number of simulations and the epsilon value (used for an epsilon-greedy exploration strategy) affect the number of states that are visited on average."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1juAMU0ZyX-d"
      },
      "outputs": [],
      "source": [
        "def txt2policy(policy_text_file):\n",
        "  # reading the data from the file\n",
        "  with open(policy_text_file) as file:\n",
        "      data = file.read()   \n",
        "  # reconstructing the data as a dictionary\n",
        "  policy = json.loads(data)\n",
        "  return {int(k):int(v) for k,v in policy.items()}\n",
        "\n",
        "def utility_file(utility, outputfilename):\n",
        "    \"\"\"Generate .policy file from policy numpy.array\n",
        "\n",
        "    Args:\n",
        "        policy (numpy.array): array of actions to take at each state\n",
        "        outputfilename (string): name of output policy file\n",
        "    \"\"\"\n",
        "    with open(outputfilename, 'w') as utility_file:\n",
        "      utility_file.write(json.dumps(utility))\n",
        "\n",
        "def policy2txt(policy_dict,policy_name):\n",
        "  with open(policy_name, 'w') as policy_file:\n",
        "      policy_file.write(json.dumps(policy_dict))\n",
        "\n",
        "def q_bellman_res(qk, q_k1):\n",
        "    \"\"\"Calculate the L_infinity norm of of the difference between the current Q function and\n",
        "    the previous Q function\n",
        "\n",
        "    Args:\n",
        "        qk (numpy.array): previous Q funciton\n",
        "        q_k1 (numpy.array): current Q function\n",
        "\n",
        "    Returns:\n",
        "        float: L_infinity norm\n",
        "    \"\"\"\n",
        "    res = np.max(np.abs(q_k1 - qk))\n",
        "    return res\n",
        "\n",
        "def q_learning(inputfilename, state_lookup, policy, q_function = None, iteration_num = 50, res_tol = 1e-9):\n",
        "    \"\"\"Q-learning algorithm for provided dataset\n",
        "\n",
        "    Args:\n",
        "          inputfilename (string): path to data file\n",
        "          state_lookup (dict): state mapping dictionary\n",
        "          res_tol (float, optional): Q-function residual. Defaults to 1e-9.\n",
        "\n",
        "    Returns:\n",
        "          numpy.array: policy extracted from action value function\n",
        "    \"\"\"\n",
        "    #states-> enumerated 0 to length-1\n",
        "    s = len(list(state_lookup.keys()))\n",
        "    #actions-> enumerated 0 to 8\n",
        "    a = 9\n",
        "\n",
        "    if q_function is not None:\n",
        "      Q_tensor = q_function\n",
        "\n",
        "    else:\n",
        "      Q_tensor = np.empty((s,a,))\n",
        "      Q_tensor[:] = -np.Inf\n",
        "\n",
        "    alpha = 0.1; gamma = 1;\n",
        "    data = pd.read_csv(inputfilename, header = None, names = ['s','a','r','sp'], \n",
        "                        dtype = {'s' : np.int64, 'a' : np.int64, 'r' : np.float64, 'sp' : np.int64})\n",
        "    iter_count = 1\n",
        "\n",
        "    # print('Begin Q-learning iterations')\n",
        "\n",
        "    #go through transitions in simulation multiple times\n",
        "    while iter_count < 20:\n",
        "      # print(f'Iteration {iter_count}')\n",
        "      for index, row in data.iterrows():\n",
        "          #map state values to enumeration with lookup dictionary\n",
        "          s_idx = state_lookup[int(row['s'])]\n",
        "          sp_idx = state_lookup[int(row['sp'])]\n",
        "          a_idx = int(row['a'])\n",
        "          r = row['r']\n",
        "\n",
        "          #Q-learning -> using the current state and action taken to transition to the next state, we updated the Q-funciton (action value function)\n",
        "          if np.max(Q_tensor[sp_idx,:]) == -np.Inf:\n",
        "            Q_max = 0\n",
        "          else:\n",
        "            Q_max = np.max(Q_tensor[sp_idx,:])\n",
        "\n",
        "          if Q_tensor[s_idx,a_idx] == -np.Inf:\n",
        "            Q_tensor[s_idx,a_idx] = 0\n",
        "\n",
        "          Q_tensor[s_idx,a_idx] += alpha*(r + gamma*Q_max - Q_tensor[s_idx,a_idx])\n",
        "      \n",
        "      # #Marta - I have a bad feeling about this...\n",
        "      # if iter_count>1:\n",
        "      #     res = q_bellman_res(Q_prev, Q_tensor)\n",
        "      #     Q_prev = np.copy(Q_tensor)\n",
        "      #     if res < res_tol:\n",
        "      #         break\n",
        "      # else:\n",
        "      #     Q_prev = np.copy(Q_tensor)\n",
        "      # print(iter_count)\n",
        "      iter_count+=1\n",
        "\n",
        "    #update given policy from Q-funciton created\n",
        "    u_function = policy.copy()\n",
        "\n",
        "    for state in list(state_lookup.keys()):\n",
        "      s_idx = state_lookup[int(state)]\n",
        "      #if we were able to fill in the action-value function at that state\n",
        "      if np.max(Q_tensor[s_idx,:]) != -np.Inf:\n",
        "        policy[state] = int(np.nanargmax(Q_tensor[s_idx,:]))\n",
        "        u_function[state] = np.nanmax(Q_tensor[s_idx,:])\n",
        "\n",
        "      else:\n",
        "        u_function[state] = -(10**9)\n",
        "\n",
        "    utility_file(u_function,'/Users/marta/Desktop/spike_data_files/utility_'+str(iteration_num)+'.txt')\n",
        "\n",
        "    unknown_count = 0\n",
        "    for state in range(s):\n",
        "      if list(Q_tensor[state,:]) == [-np.inf for i in range(a)]:\n",
        "        unknown_count+=1\n",
        "\n",
        "    return policy, Q_tensor, unknown_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "hTuZBNbxEWmb",
        "outputId": "6e0a3ee2-88d6-4161-a5d6-a481f1366655"
      },
      "outputs": [],
      "source": [
        "#set up learning routine\n",
        "iter = 0\n",
        "tot_iter = 50\n",
        "#parameters for running the simulation\n",
        "n_player = 2\n",
        "n_hands = 10\n",
        "epsilon = 0.9\n",
        "alpha = 0.9556                     # this means that after 50 iterations, the epsilon parameter is 9.722398597662178 %\n",
        "q_function = None\n",
        "not_seen_counts = []\n",
        "win_credits_reward = True\n",
        "\n",
        "#generate a random policy and save it\n",
        "policy, state_lookup = generate_policy(n_player,fold=2)\n",
        "random_policy = policy.copy()\n",
        "policy2txt(random_policy,'/Users/marta/Desktop/spike_data_files/random_policy.txt')\n",
        "\n",
        "while iter<tot_iter:\n",
        "  for sim in range(2000):\n",
        "    #in evaluating the policy, make it so that different players run on different policies\n",
        "    #evaluate based on  - most money gained in a game\n",
        "    simulation = CorellianSpike(policy,n=n_player, epsilon=epsilon, win_credits = win_credits_reward)\n",
        "    wins = simulation.play_sabacc(k=n_hands)\n",
        "\n",
        "  print(f'Q-learning, iteration {iter}')\n",
        "  inputfilename = '/Users/marta/Desktop/spike_data.txt'\n",
        "  policy, q_function, tot_not_seen_states = q_learning(inputfilename, state_lookup, policy, q_function = q_function, iteration_num=iter)\n",
        "\n",
        "  not_seen_counts.append(tot_not_seen_states)\n",
        "  #record intermediate policies for further evaluation\n",
        "  if (iter+1)%5 ==0:\n",
        "    mid_policy = policy.copy()\n",
        "    policy2txt(mid_policy,'/Users/marta/Desktop/spike_data_files/mid_policy_'+str(iter+1)+'.txt')\n",
        "\n",
        "  #delete file to stop appending\n",
        "  os.remove(inputfilename)\n",
        "\n",
        "  #update the epsilon parameter\n",
        "  epsilon = epsilon*alpha\n",
        "  iter+=1\n",
        "\n",
        "optimal_policy = policy.copy()\n",
        "policy2txt(optimal_policy,'/Users/marta/Desktop/spike_data_files/optimal_policy.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qao6d0hu0d3"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(7,4))\n",
        "plt.plot(range(len(not_seen_counts)) ,not_seen_counts)\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Total unexplored states')\n",
        "plt.grid()\n",
        "plt.xlim(0)\n",
        "plt.tight_layout()\n",
        "fig.savefig('unseen_states.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBY52PSdUFvG"
      },
      "source": [
        "# Policy Evaluation\n",
        "\n",
        "This runs n_sim simulations for n_player players and n_hands hands and outputs how often each policy wins, how much money is gained/lost on average, and how many times each policy completely runs out of money. Which policies are being compared can be changed by importing different policies and changing which are included in the variable policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaiqQ3FesAKf",
        "outputId": "3f8f954a-5046-4f50-8f0c-1406ac059db1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average money gained: [-1.152  0.955 -1.466 -0.736 -0.619  3.14   1.087 -1.209]\n",
            "Win Rate: [0.121   0.13775 0.1135  0.1195  0.12    0.142   0.1305  0.11575]\n",
            "Bust Count: [0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "11003\n"
          ]
        }
      ],
      "source": [
        "from pandas.io.parquet import read_parquet\n",
        "n_player = 8 #number of players\n",
        "n_sim = 2000 #number of sims\n",
        "n_hands = 2\n",
        "win_counts = np.zeros(n_player) # running count of hands won across all games\n",
        "money = np.zeros(n_player)      # running count of money gained or lost across all games\n",
        "# policy, state_lookup = generate_policy(n_player, fold = 2)\n",
        "randpol, state_lookup = generate_policy(2)\n",
        "#mid = txt2policy(\"/content/drive/MyDrive/Winter 2022/AA 228/first_spike_run/marta data/mid_policy_25.txt\")\n",
        "multi = txt2policy(\"/content/drive/MyDrive/Winter 2022/AA 228/first_spike_run/izzie data/data/optimal_policy.txt\")\n",
        "#policy2, state_lookup = generate_policy(n_player,fold = 2)\n",
        "#mon_pol = txt2policy(\"/content/drive/MyDrive/Winter 2022/AA 228/first_spike_run/max data/win_credits_true/spike_data_files/optimal_policy.txt\")\n",
        "oth_pol = txt2policy(\"/content/drive/MyDrive/Winter 2022/AA 228/first_spike_run/marta data/optimal_policy.txt\")\n",
        "#ss_pol = txt2policy(\"/content/drive/MyDrive/Winter 2022/AA 228/first_spike_run/starship data/optimal_policy.txt\")\n",
        "#policy = [policy, policy2]\n",
        "policy = [oth_pol,multi,randpol,randpol,randpol,randpol,randpol,randpol]\n",
        "states = set()\n",
        "\n",
        "bust = np.zeros(n_player)\n",
        "\n",
        "total_wins = 0\n",
        "for sim in range(n_sim):\n",
        "  #in evaluating the policy, make it so that different players run on different policies\n",
        "  #evaluate based on  - most money gained in a game\n",
        "  order = np.arange(n_player)\n",
        "  np.random.shuffle(order)\n",
        "  #print(order)\n",
        "  policy_shuffled = []\n",
        "  for i in order:\n",
        "    policy_shuffled.append(policy[i])\n",
        "\n",
        "  simulation = CorellianSpike(policy_shuffled,n=n_player,connect=True)\n",
        "  wins = simulation.play_sabacc(k=n_hands)\n",
        "  #print(wins)\n",
        "  temp_w = []\n",
        "  for i in order:\n",
        "    temp_w.append(wins[i])\n",
        "  wins = np.array(temp_w)\n",
        "  #print(wins)\n",
        "  states = states.union(simulation.states)\n",
        "  \n",
        "  for p in range(n_player):\n",
        "    if simulation.players[order[p]]['money'] == 0:\n",
        "      bust[p]+=1\n",
        "\n",
        "  win_counts += wins\n",
        "  total_wins += np.sum(wins)\n",
        "  #self.players[player]['money']\n",
        "  temp_money = np.zeros(n_player)\n",
        "  for player in range(n_player):\n",
        "    temp_money[player] += (simulation.players[order[player]]['money']-50)\n",
        "  money += temp_money\n",
        "  #print(temp_money)\n",
        "  #print(\" \")\n",
        "\n",
        "avg_money_gained = money/n_sim\n",
        "win_rate = win_counts/total_wins\n",
        "print(f'Average money gained: {avg_money_gained}')\n",
        "print(f'Win Rate: {win_rate}')\n",
        "print(f'Bust Count: {bust}')\n",
        "print(len(states))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiRzlygUUnkX"
      },
      "source": [
        "# Play against the computer!\n",
        "\n",
        "After generating a policy, change policy to the name of the policy you would like to play against. Change k=1 in order to change the number of hands you play."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eJ2T8NoajOX"
      },
      "outputs": [],
      "source": [
        "human_sim = CorellianSpike(policy,human=True)\n",
        "human_sim.play_sabacc(k=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Action Distribution Plots!\n",
        "\n",
        "Run the following cells to generate the same action distribution plots as given in the final report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "directory = '/Users/marta/Desktop/spike_data_files_no_win_reward/policies'\n",
        "all_policies = {key:{} for key in [filename[:-4] for filename in os.listdir(directory)]}\n",
        "r_policy, state_lookup = generate_policy(2)\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "    policy = txt2policy(f)\n",
        "    # checking if it is a file\n",
        "    all_policies[filename[:-4]] = policy\n",
        "\n",
        "\n",
        "plot_order = ['random_policy', 'mid_policy_5', 'mid_policy_10', 'mid_policy_15', 'mid_policy_20', 'mid_policy_25', 'mid_policy_30','mid_policy_35', 'mid_policy_40', 'mid_policy_45', 'optimal_policy']\n",
        "\n",
        "state_list = list(state_lookup.keys())\n",
        "\n",
        "r0d1_states = [int(key) for key in state_list if int(key)<10000000 and int(key)>0]\n",
        "\n",
        "r1d1_states = [int(key) for key in state_list if int(key)>=11000000 and int(key)<12000000]\n",
        "r1d2_states = [int(key) for key in state_list if int(key)>=12000000 and int(key)<13000000]\n",
        "r1d3_states = [int(key) for key in state_list if int(key)>=13000000 and int(key)<20000000]\n",
        "\n",
        "r2d1_states = [int(key) for key in state_list if int(key)>=21000000 and int(key)<22000000]\n",
        "r2d2_states = [int(key) for key in state_list if int(key)>=22000000 and int(key)<23000000]\n",
        "r2d3_states = [int(key) for key in state_list if int(key)>=23000000 and int(key)<30000000]\n",
        "\n",
        "r3d1_states = [int(key) for key in state_list if int(key)>=31000000 and int(key)<32000000]\n",
        "r3d2_states = [int(key) for key in state_list if int(key)>=32000000 and int(key)<33000000]\n",
        "r3d3_states = [int(key) for key in state_list if int(key)>=33000000]\n",
        "\n",
        "r0d1_actions = []; r1d1_actions = []; r1d2_actions = []; r1d3_actions = []\n",
        "r2d1_actions = []; r2d2_actions = []; r2d3_actions = []\n",
        "r3d1_actions = []; r3d2_actions = []; r3d3_actions = []\n",
        "\n",
        "for key in plot_order:\n",
        "    policy =  all_policies[key]\n",
        "\n",
        "    r0d1 = [policy[state] for state in r0d1_states]\n",
        "    r0d1_actions.append([r0d1.count(0)/len(r0d1),r0d1.count(1)/len(r0d1),(len(r0d1)-r0d1.count(0)-r0d1.count(1))/len(r0d1)])\n",
        "\n",
        "    r1d1 = [policy[state] for state in r1d1_states]\n",
        "    r1d1_actions.append([r1d1.count(0)/len(r1d1),r1d1.count(1)/len(r1d1),(len(r1d1)-r1d1.count(0)-r1d1.count(1))/len(r1d1)])\n",
        "    r1d2 = [policy[state] for state in r1d2_states]\n",
        "    r1d2_actions.append([r1d2.count(3)/len(r1d2),r1d2.count(4)/len(r1d2)])\n",
        "    r1d3 = [policy[state] for state in r1d3_states]\n",
        "    r1d3_actions.append([r1d3.count(5)/len(r1d3),r1d3.count(6)/len(r1d3),r1d3.count(7)/len(r1d3), r1d3.count(8)/len(r1d3)])\n",
        "\n",
        "    r2d1 = [policy[state] for state in r2d1_states]\n",
        "    r2d1_actions.append([r2d1.count(0)/len(r2d1),r2d1.count(1)/len(r2d1),(len(r2d1)-r2d1.count(0)-r2d1.count(1))/len(r2d1)])\n",
        "    r2d2 = [policy[state] for state in r2d2_states]\n",
        "    r2d2_actions.append([r2d2.count(3)/len(r2d2),r2d2.count(4)/len(r2d2)])\n",
        "    r2d3 = [policy[state] for state in r2d3_states]\n",
        "    r2d3_actions.append([r2d3.count(5)/len(r2d3),r2d3.count(6)/len(r2d3),r2d3.count(7)/len(r2d3), r2d3.count(8)/len(r2d3)])\n",
        "\n",
        "    r3d1 = [policy[state] for state in r3d1_states]\n",
        "    r3d1_actions.append([r3d1.count(0)/len(r3d1),r3d1.count(1)/len(r3d1),(len(r3d1)-r3d1.count(0)-r3d1.count(1))/len(r3d1)])\n",
        "    r3d2 = [policy[state] for state in r3d2_states]\n",
        "    r3d2_actions.append([r3d2.count(3)/len(r3d2),r3d2.count(4)/len(r3d2)])\n",
        "    r3d3 = [policy[state] for state in r3d3_states]\n",
        "    r3d3_actions.append([r3d3.count(5)/len(r3d3),r3d3.count(6)/len(r3d3),r3d3.count(7)/len(r3d3), r3d3.count(8)/len(r3d3)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x =  ['Initial', 'Iteration 5', 'Iteration 10', 'Iteration 15', 'Iteration 20', 'Iteration 25', 'Iteration 30','Iteration 35', 'Iteration 40', 'Iteration 45', 'Final']\n",
        "\n",
        "size_fig = (13.5,2.5)\n",
        "\n",
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r0d1_actions]\n",
        "y1 = [a[1] for a in r0d1_actions]\n",
        "y2 = [a[2] for a in r0d1_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Raise')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'Match')\n",
        "plt.bar(x, y2, bottom=np.array(y0)+np.array(y1), color='tab:green',label = 'Fold')\n",
        "plt.xlabel('Policies')\n",
        "plt.title('Round 0 Decision 1')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.ylim(0,1.1)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig.savefig('r0d1.png')\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r1d1_actions]\n",
        "y1 = [a[1] for a in r1d1_actions]\n",
        "y2 = [a[2] for a in r1d1_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Raise')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'Match')\n",
        "plt.bar(x, y2, bottom=np.array(y0)+np.array(y1), color='tab:green',label = 'Fold')\n",
        "plt.xlabel('Policies')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.title('Round 1 Decision 1')\n",
        "plt.ylim(0,1.1)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig.savefig('r1d1.png')\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r2d1_actions]\n",
        "y1 = [a[1] for a in r2d1_actions]\n",
        "y2 = [a[2] for a in r2d1_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Raise')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'Match')\n",
        "plt.bar(x, y2, bottom=np.array(y0)+np.array(y1), color='tab:green',label = 'Fold')\n",
        "plt.xlabel('Policies')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.title('Round 2 Decision 1')\n",
        "plt.ylim(0,1.1)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig.savefig('r2d1.png')\n",
        "\n",
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r3d1_actions]\n",
        "y1 = [a[1] for a in r3d1_actions]\n",
        "y2 = [a[2] for a in r3d1_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Raise')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'Match')\n",
        "plt.bar(x, y2, bottom=np.array(y0)+np.array(y1), color='tab:green',label = 'Fold')\n",
        "plt.xlabel('Policies')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.title('Round 3 Decision 1')\n",
        "plt.ylim(0,1.1)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig.savefig('r3d1.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r1d2_actions]\n",
        "y1 = [a[1] for a in r1d2_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Buy card')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'No card bought')\n",
        "plt.xlabel('Policies')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.ylim(0,1.1)\n",
        "plt.title('Round 1 Decision 2')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig.savefig('r1d2.png')\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r2d2_actions]\n",
        "y1 = [a[1] for a in r2d2_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Buy card')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'No card bought')\n",
        "plt.xlabel('Policies')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.ylim(0,1.1)\n",
        "plt.title('Round 2 Decision 2')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig.savefig('r2d2.png')\n",
        "\n",
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r3d2_actions]\n",
        "y1 = [a[1] for a in r3d2_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Buy card')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'No card bought')\n",
        "plt.xlabel('Policies')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.title('Round 3 Decision 2')\n",
        "plt.ylim(0,1.1)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig.savefig('r3d2.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r1d3_actions]\n",
        "y1 = [a[1] for a in r1d3_actions]\n",
        "y2 = [a[2] for a in r1d3_actions]\n",
        "y3 = [a[3] for a in r1d3_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Discard')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'Swap with spike')\n",
        "plt.bar(x, y2, bottom=np.array(y0)+np.array(y1), color='tab:green',label = 'Swap with lower hand card')\n",
        "plt.bar(x, y3, bottom=np.array(y0)+np.array(y1)+np.array(y2), color='tab:purple',label = 'Swap with higher hand card')\n",
        "plt.xlabel('Policies')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.ylim(0,1.1)\n",
        "plt.legend()\n",
        "plt.title('Round 1 Decision 3')\n",
        "plt.tight_layout()\n",
        "fig.savefig('r1d3.png')\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r2d3_actions]\n",
        "y1 = [a[1] for a in r2d3_actions]\n",
        "y2 = [a[2] for a in r2d3_actions]\n",
        "y3 = [a[3] for a in r2d3_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Discard')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'Swap with spike')\n",
        "plt.bar(x, y2, bottom=np.array(y0)+np.array(y1), color='tab:green',label = 'Swap with lower hand card')\n",
        "plt.bar(x, y3, bottom=np.array(y0)+np.array(y1)+np.array(y2), color='tab:purple',label = 'Swap with higher hand card')\n",
        "plt.xlabel('Policies')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.ylim(0,1.1)\n",
        "plt.legend()\n",
        "plt.title('Round 2 Decision 3')\n",
        "plt.tight_layout()\n",
        "fig.savefig('r2d3.png')\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=size_fig)\n",
        "y0 = [a[0] for a in r3d3_actions]\n",
        "y1 = [a[1] for a in r3d3_actions]\n",
        "y2 = [a[2] for a in r3d3_actions]\n",
        "y3 = [a[3] for a in r3d3_actions]\n",
        "# plot bars in stack manner\n",
        "plt.bar(x, y0, color='tab:blue', label = 'Discard')\n",
        "plt.bar(x, y1, bottom=y0, color='tab:orange',label = 'Swap with spike')\n",
        "plt.bar(x, y2, bottom=np.array(y0)+np.array(y1), color='tab:green',label = 'Swap with lower hand card')\n",
        "plt.bar(x, y3, bottom=np.array(y0)+np.array(y1)+np.array(y2), color='tab:purple',label = 'Swap with higher hand card')\n",
        "plt.xlabel('Policies')\n",
        "plt.ylabel(r'Action distribution')\n",
        "plt.ylim(0,1.1)\n",
        "plt.title('Round 3 Decision 3')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "fig.savefig('r3d3.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "44a9cdcbdccbf05a880e90d2e6fe72470baab4d1b82472d890be0596ed887a6b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
